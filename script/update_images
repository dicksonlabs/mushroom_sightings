#!/usr/bin/env ruby
#
#  USAGE::
#
#    script/update_images [mode] [args...]
#
#  DESCRIPTION::
#
#  This is the daemon that moves images to the remote image servers.  Run the
#  script with --help to get full set of modes of operation and arguments.
#
################################################################################

# Default delay between checks for new images in daemon mode.
DAEMON_DELAY = 60

# Number of seconds between progress updates.
PROGRESS_DELAY = 10

# Number of times to retry upload/download before giving up.
RETRIES = 5

# Default root path for Rails.
ROOT = '/var/web/mo'
# ROOT = '/home/jason/public_html/mo_trunk'

# Where pid of daemon is stored by default.
PID_FILE = 'tmp/pids/update_images.pid'

# Where daemon and cronjob log stuff by default.
LOG_FILE = 'log/update_images.log'

# Default local path (where daemon runs).
LOCAL_PATH = 'public/images'

# Aliases for our image servers.
SERVER_ALIASES = {
  'dreamhost' => 'velosa@images.mushroomobserver.org:images.mushroomobserver.org',
  'slicehost' => 'mushroomobserver.org:/var/web/mo/public/images',
# 'dreamhost' => 'velosa@images.mushroomobserver.org:images.mushroomobserver.org/test',
# 'slicehost' => 'mushroomobserver.org:test',
}

# List of official image servers to keep updated from main webserver.
OFFICIAL_SERVERS = [
  'dreamhost'
]

# Default image server to use for --sync mode.
DEFAULT_IMAGE_SERVER = 'dreamhost'

# ----------------------------
#  Command line parsing.
# ----------------------------

# Is first argument a value or a flag?
def is_next_arg_value?
  @argv ||= ARGV
  @argv.first && @argv.first[0,1] != '-'
end

# Get and remove first argument.
def get_next_arg
  @argv ||= ARGV
  @argv.shift
end

# Look for and remove a bare flag: '--thumb'
def get_flag(arg)
  @argv ||= ARGV
  result = nil
  if i = @argv.index(arg)
    @argv.delete_at(i)
    result = true
  end
  return result
end

# Look for and remove an argument with a value: '--path blah'
def get_parm(arg)
  @argv ||= ARGV
  result = nil
  if i = @argv.index(arg)
    result = @argv[i+1]
    @argv.delete_at(i)
    @argv.delete_at(i)
  end
  return result
end

# Make sure there are no unexpected arguments, dying if there are.
def any_args_left?
  @argv ||= ARGV
  if !@argv.empty?
    puts "Unexpected arguments: [#{@argv.join(', ')}]\n"
    exit 1
  end
end

# ----------------------------
#  Nightly job.
# ----------------------------

def refresh_listings(cronjob=false)
  log("Refreshing listings\n") if cronjob
  files = {}

  # Get local list for diagnostic purposes only.
  log("Getting local listing\n") if cronjob
  puts "Getting local listing...\n"
  files['local'] = list = list_local_files(@@local_path)
  puts "  thumb: #{list.keys.select {|f| f[0,5] == 'thumb'}.length}\n"
  puts "  640:   #{list.keys.select {|f| f[0,3] == '640'}.length}\n"
  puts "  orig:  #{list.keys.select {|f| f[0,4] == 'orig'}.length}\n"
  write_cached_file_list('local', list)

  # Get remote lists so we can refresh the caches.
  for server in OFFICIAL_SERVERS
    log("Getting #{server} listing\n") if cronjob
    puts "Getting #{server} listing...\n"
    if list = list_remote_files(server)
      write_cached_file_list(server, list)
      puts "  thumb: #{list.keys.select {|f| f[0,5] == 'thumb'}.length}\n"
      puts "  640:   #{list.keys.select {|f| f[0,3] == '640'}.length}\n"
      puts "  orig:  #{list.keys.select {|f| f[0,4] == 'orig'}.length}\n"
      files[server] = list
    else
      log("  (failed)\n") if cronjob
      puts "  server is down\n"
    end
  end

  # Look for and complain about mismatches.
  check_for_mismatches(files, cronjob)
end

# This takes a hash of file-list hashes and checks for mismatches in size
def check_for_mismatches(file_lists, cronjob=false)
  servers = file_lists.keys.sort

  # Get union of files on all servers.
  files = {}
  for server in servers
    for file in file_lists[server].keys
      files[file] = nil
    end
  end

  # Get list of files with mismatches.
  mismatches = files.keys.select do |file|
    size = nil
    any_different = false
    any_missing   = false

    if file != 'date'
      for server in servers
        size2 = file_lists[server][file]
        any_different = true if size && size2 && size != size2
        any_missing = true   if !size2
        size = size2         if !size
      end

      # Remove originals if they exist and are correct on all remote servers.
      if cronjob && !any_different && !any_missing && file[0,4] == 'orig'
        File.delete("#{@@local_path}/#{file}")
        verbose("deleting #{file}")
        log("Deleting #{file}\n")
      end
    end

    any_different
  end

  # Now print out the list of problems in a table.
  if !mismatches.empty?
    str = "Found #{mismatches.length} mismatch(es):\n\n"

    str += sprintf("%-20s %s\n", 'file', servers.map do |server|
      sprintf('%15s', server)
    end.join(' '))

    for file in mismatches
      str += sprintf("%-20s %s\n", file, servers.map do |server|
        size = file_lists[server][file]
        size ? sprintf('%15d', size) : sprintf('%15s', '--')
      end.join(' '))
    end

    puts str
    log(str + "\n") if cronjob
  end
end

# ----------------------------
#  Daemon.
# ----------------------------

def daemon(delay)
  log_break
  log("Starting daemon\n")
  local_files = {}     # local_files['orig/1234.jpg'] = 123456 (bytes)
  remote_files = {}    # remote_files['dreamhost']['orig/1234.jpg'] = 123456
  server_status = {}   # server_status['dreamhost'] = ServerStatus instance

  # Get initial list of files on local and remote servers.
  log("Getting local listing\n")
  local_files = list_local_files(@@local_path)
  for server in OFFICIAL_SERVERS
    server_status[server] = status = ServerStatus.new(server)
    list = get_cached_file_list(server)
    if !list
      log("Getting #{server} listing\n")
      list = list_remote_files(server)
      if list
        write_cached_file_list(server, list)
      else
        log("  (failed)\n")
        status.listing_failed
      end
    end
    remote_files[server] = list
  end

  while true
    # Look for any new files.
    update_file_cache(local_files, 'local')
    update_local_files(local_files, @@local_path)

    # Attempt to transfer any files not on any of the remote servers.
    # This will work continuously until done or the server fails.
    for server in OFFICIAL_SERVERS
      status = server_status[server]
      if status.okay_to_upload?
        update_file_cache(remote_files[server], server)
        for file in local_files.keys - remote_files[server].keys
          log("Transferring #{file} to #{server}\n")
          if transfer_file(file, @@local_path, server)
            status.upload_worked
            remote_files[server][file] = size = local_files[file]
            add_file_to_cached_file_list(server, file, size)
          else
            log("  (failed)\n")
            status.upload_failed
            if !status.okay_to_upload?
              break
            end
          end
        end
      end
    end

    # Wait for a bit before checking for new files.
    sleep delay
  end
end

# -----------------------------
#  Command-line utility mode.
# -----------------------------

def sync_command(local,remote, do_upload,do_download, do_thumb,do_640,do_orig, use_cache)
  local_files = {}     # local_files['orig/1234.jpg'] = 123456 (bytes)
  remote_files = {}    # remote_files['orig/1234.jpg'] = 123456

  # Get initial list of files locally and on remote server.
  puts "Getting local listing...\n"
  if use_cache
    local_files = get_cached_file_list('local')
  else
    local_files = list_local_files(local)
    write_cached_file_list('local', local_files)
  end
  puts "Getting remote listing...\n"
  if use_cache
    remote_files = get_cached_file_list(remote)
  else
    remote_files = list_remote_files(remote)
    write_cached_file_list(remote, remote_files)
  end
  check_for_mismatches('local' => local_files, 'remote' => remote_files)

  # Upload files missing on remote server.
  if do_upload
    files = []
    size = 0
    for file in local_files.keys - remote_files.keys
      if do_thumb && file[0..4] == 'thumb' ||
         do_640   && file[0..2] == '640'   ||
         do_orig  && file[0..3] == 'orig'
        files.push(file)
        size += local_files[file]
      end
    end
    if files.empty?
      puts "Nothing to upload.\n"
    else
      puts "Uploading #{size} bytes in #{files.length} file(s)...\n"
      upload_files(files, local, remote)
    end
  end

  # Download files missing locally.
  if do_download
    files = []
    size = 0
    for file in remote_files.keys - local_files.keys
      if do_thumb && file[0..4] == 'thumb' ||
         do_640   && file[0..2] == '640'   ||
         do_orig  && file[0..3] == 'orig'
        files.push(file)
        size += remote_files[file]
      end
    end
    if files.empty?
      puts "Nothing to download.\n"
    else
      puts "Downloading #{size} bytes in #{files.length} file(s)...\n"
      download_files(files, local, remote)
    end
  end
end

# ----------------------------
#  Daemon administration.
# ----------------------------

# Get pid of the daemon.
def daemon_pid
  pid = nil
  if File.exists?(@@pid_file)
    open(@@pid_file) do |fh|
      line = fh.gets
      pid = line.chomp.to_i if line
    end
  end
  return pid
end

# Write daemon's pid to the official pid file.
def save_daemon_pid(pid)
  open(@@pid_file, 'w') do |fh|
    fh.puts(pid.to_s)
  end
end

# Check if the daemon is up and running by doing a 'ps' on it.
def is_daemon_running?
  status = false
  if pid = daemon_pid
    status = true if is_running?(pid)
  end
  return status
end

# Check if a given process is running by doing a 'ps' on it.
def is_running?(pid)
  status = false
  open("|ps -p #{pid}") do |ps|
    ps.gets
    status = true if ps.gets
  end
  return status
end

# Start the daemon, trapping HUP signals so that other processes can interrupt
# its sleep by sending it a HUP signal.
def start_daemon(delay)
  result = false
  pid = Process.fork do
    Signal.trap('HUP') do
      log("Prodded")
    end
    Signal.trap('TERM') do
      log("Killed")
      exit 0
    end
    daemon(delay)
    exit 1
  end
  if pid
    save_daemon_pid(pid)
    result = true
  end
  return result
end

# Send daemon a HUP signal to get it to check for new images immediately.
def prod_daemon
  result = false
  if pid = daemon_pid
    Process.kill("HUP", pid)
    result = true
  end
  return result
end

# Kill the daemon.  Waits several seconds for it to die.  If the process
# goes away, it deletes the pid file.
def kill_daemon
  result = false
  pid = daemon_pid
  Process.kill("TERM", pid)
  # Wait up to five seconds for it to stop.
  for i in [1..5]
    sleep 1
    if !is_running?(pid)
      File.delete(@@pid_file)
      result = true
      break
    end
  end
  return result
end

# ---------------------------------
#  Logging and verbose messaging.
# ---------------------------------

def log_break
  if File.exists?(@@log_file)
    open(@@log_file, 'a') do |fh|
      fh.puts ''
    end
  end
end

def log(msg)
  open(@@log_file, 'a') do |fh|
    time = Time.now.strftime('[%Y%m%d:%H:%M:%S] ')
    fh.puts(time + msg)
  end
end

def verbose(msg)
  if @@verbose
    puts msg.gsub(/^/, '  ')
  end
end

# ----------------------------
#  Get file lists.
# ----------------------------

# Get list of local images.  Returns a hash whose keys are filenames (without
# path, just 'thumb/1234.jpg') and whose values are file sizes.
def list_local_files(path)
  files = {}
  files['date'] = Time.now
  for type in ['thumb', '640', 'orig']
    cmd = "ls -lU --color=never #{path}/#{type}"
    verbose cmd
    open("|#{cmd}") do |dir|
n = 0
      dir.each_line do |line|
puts "DIR: [#{line.inspect}]" if n < 10
        size, file = line.chomp.split.values_at(4, 7)
puts "SIZE=#{size.inspect} FILE=#{file.inspect}" if n < 10
        if file && file.match(/^\d+\.jpg$/) && size.to_i != 0
          files["#{type}/#{file}"] = size.to_i
        end
n += 1
      end
    end
  end
  return files
end

# Get list of images on a remote server.  The +server+ parameter can be an
# alias of an established image server, or a scp-style url (user@host:path).
def list_remote_files(server)
  url = SERVER_ALIASES[server] || server
  if url.index(':')
    url, path = url.split(':')
  else
    path = '.'
  end
  files = {}
  files['date'] = Time.now
  cmd = "ssh #{url} ls -lU --color=never #{path}/{thumb,640,orig}"
  verbose cmd
  open("|#{cmd}") do |dir|
    type = nil
    dir.each_line do |line|
      if line.chomp.match(/^\S+\/(\w+):$/)
        type = $1
      else
        size, file = line.chomp.split.values_at(4, 7)
        if file && file.match(/^\d+\.jpg$/) && size.to_i != 0
          files["#{type}/#{file}"] = size.to_i
        end
      end
    end
  end
  return files
end

# Look for new images locally by just doing a directory of originals -- this
# directory should be nearly empty at all times, with only the latest images
# in it that haven't been transferred to the image servers yet.
def update_local_files(files, path)
  Dir.foreach("#{path}/orig") do |file|
    if file.match(/^\d+\.jpg$/) && !files.has_key?("orig/#{file}")
      file1 = "#{path}/thumb/#{file}"
      file2 = "#{path}/640/#{file}"
      file3 = "#{path}/orig/#{file}"
      # Wait for all three images, otherwise the daemon might wake up after
      # the original has been uploaded but before the smaller sizes have been
      # created.  That would result in the smaller sizes being missed until
      # the nightly job finally caught the error.
      if File.exists?(file1) && (size1 = File.size(file1).to_i) != 0
         File.exists?(file2) && (size2 = File.size(file2).to_i) != 0
         File.exists?(file3) && (size3 = File.size(file3).to_i) != 0
        files["thumb/#{file}"] = size1
        files["640/#{file}"]   = size2
        files["orig/#{file}"]  = size3
        log "Found new image #{file}\n"
      end
    end
  end
  return files
end

# ----------------------------
#  File listing caches.
# ----------------------------

# Get cached directory.  Returns a hash whose keys are filenames (no path, just
# 'thumb/1234.jpg'), and whose values are the size of the file in bytes.  The
# +server+ parameter is either 'local' or an alias for an remote image server.
def get_cached_file_list(server)
  files = nil
  cache_file = "#{@@local_path}/#{server}.files"
  if File.exists?(cache_file)
    files = {}
    verbose "reading #{@@local_path}/#{server}.files"
    open(cache_file) do |fh|
      fh.each_line do |line|
        file, size = line.chomp.split
        files[file] = size.to_i
      end
    end
    files['date'] = File.mtime(cache_file)
  end
  return files
end

# Write directory cache.
def write_cached_file_list(server, files)
  verbose "writing #{@@local_path}/#{server}.files"
  open("#{@@local_path}/#{server}.files", 'w') do |fh|
    files.each_pair do |file, size|
      fh.puts("#{file} #{size}\n")
    end
  end
  files['date'] = Time.now
end

# Add a file that was just transferred.
def add_file_to_cached_file_list(server, file, size)
  verbose "adding '#{file} #{size}' to #{@@local_path}/#{server}.files"
  open("#{@@local_path}/#{server}.files", 'a') do |fh|
    fh.puts("#{file} #{size}\n")
  end
end

# Check if cached directory for the given server has been refreshed.  (This
# is used by the daemon which is running continuously.  It checks each cycle
# to see if the nightly --clean job has run, and refreshes its internal cache
# accordingly when it has.  This will theoretically catch those rare cases
# where it *looks* like a transfer has worked, but for some reason hasn't.)
# Returns nothing; changes file list in place as necessary.
def update_file_cache(files, server)
  file = "#{@@local_path}/#{server}.files"
  if File.exists?(file) && File.mtime(file) > files['date']
    log("Daemon refreshing #{server} listing")
    new_files = get_cached_file_list(server)
    if new_files
      files.replace(new_files)
    end
  end
end

# ----------------------------
#  File transfers.
# ----------------------------

# Upload/download a single file.
def transfer_file(file, from, to)
  from = SERVER_ALIASES[from] if SERVER_ALIASES.has_key?(from)
  to   = SERVER_ALIASES[to]   if SERVER_ALIASES.has_key?(to)
  cmd  = "scp #{from}/#{file} #{to}/#{file}"
  verbose cmd
  system cmd
end

# Upload a list of files.
def upload_files(files, local, remote)
  remote = SERVER_ALIASES[remote] if SERVER_ALIASES.has_key?(remote)
  if remote.index(':')
    url, path = remote.split(':')
  else
    url  = remote
    path = '.'
  end

  tempfile = "/tmp/update_images.#{$$}"
  open(tempfile, 'w') do |fh|
    for file in files.sort
      fh.puts(file)
    end
  end

  cmd = "tar -T #{tempfile} -cf - | ssh #{url} \\(cd #{path}\\; tar -xvf -\\)"
  verbose cmd

  save = Dir.getwd
  Dir.chdir(local)
  open("|#{cmd}") do |fh|
    fh.each_line do |line|
      verbose line
    end
  end
  Dir.chdir(save)

  File.delete(tempfile)
end

# Download a list of files.
def download_files(files, local, remote)
  remote = SERVER_ALIASES[remote] if SERVER_ALIASES.has_key?(remote)
  if remote.index(':')
    url, path = remote.split(':')
  else
    url  = remote
    path = '.'
  end

  tempfile = "/tmp/update_images.#{$$}"
  open(tempfile, 'w') do |fh|
    for file in files.sort
      fh.puts(file)
    end
  end

  cmd = "cat #{tempfile} | ssh #{url} \\(cd #{path}\\; tar -T - -cf -\\) | tar -xvf -"
  verbose cmd

  save = Dir.getwd
  Dir.chdir(local)
  open("|#{cmd}") do |fh|
    fh.each_line do |line|
      verbose line
    end
  end
  Dir.chdir(save)

  File.delete(tempfile)
end

# -------------------------------
#  Keep track of server status.
# -------------------------------

# Class used to keep track of status of each server, and whether or not we are
# willing to try to use it.  The current logic is: we start assuming it is
# okay, if an upload fails we move on to the next file and try up to 5 files
# if they all fail, we disable the server for 10 minutes, then try again.  If
# any upload ever works it resets the counter.
class ServerStatus
  def initialize(name)
    @name   = name   # server name for log
    @fails  = 0      # number of times it's failed
    @cycles = 0      # number of cycles until we try again
    @alert  = false  # will log server is back up if true
  end

  # Call this to tell it that an upload worked.
  def upload_worked
    log("Server #{@name} is back up") if @alert
    @fails  = 0
    @cycles = 0
    @alert  = false
  end

  # Call this to tell it that an upload failed.
  def upload_failed
    @fails += 1
    log("Server #{@name} is down") if @fails == 5
  end

  # Call this to tell it that it failed to return a directory listing.
  def listing_failed
    @fails  = 5
    @cycles = 0
    log("Server #{@name} is down")
  end

  # Call this to determine if you should try to use the server.
  def okay_to_upload?
    status = false
    if @fails < 5
      status  = true
    elsif @cycles >= 10
      @fails  = 0
      @cycles = 0
      @alert  = true
      status  = true
    else
      @cycles += 1
    end
    return status
  end
end

# ----------------------------
#  Main program.
# ----------------------------

# Turn on verbose messages.
@@verbose = get_flag('-v') || get_flag('--verbose')

# Let user override some of the defaults.
@@root       = get_parm('-R') || get_parm('--root')       || ROOT
@@pid_file   = get_parm('-F') || get_parm('--pid-file')   || "#{@@root}/#{PID_FILE}"
@@log_file   = get_parm('-L') || get_parm('--log-file')   || "#{@@root}/#{LOG_FILE}"
@@local_path = get_parm('-P') || get_parm('--local-path') || "#{@@root}/#{LOCAL_PATH}"

case get_next_arg
  when '-d', '--start'
    delay = (is_next_arg_value? ? get_next_arg : DAEMON_DELAY).to_i
    any_args_left?
    if is_daemon_running? || start_daemon(delay)
      exit 0
    else
      puts "Failed to start daemon.\n"
      exit 1
    end

  when '-r', '--restart'
    delay = (is_next_arg_value? ? get_next_arg : DAEMON_DELAY).to_i
    any_args_left?
    if is_daemon_running?
      kill_daemon
    end
    if start_daemon(delay)
      exit 0
    else
      puts "Failed to start daemon.\n"
      exit 1
    end

  when '-k', '--stop'
    any_args_left?
    if is_daemon_running?
      kill_daemon
      exit 0
    else
      puts "Daemon is not running.\n"
      exit 1
    end

  when '-p', '--prod'
    # This isn't interrupting the sleep command in the main event loop.
    # We'll need to have it wake up more often and check if it's been prodded?
    puts "Prodding sleeping daemons is a bad idea."
    exit 1
    any_args_left?
    if is_daemon_running?
      prod_daemon
      exit 0
    else
      puts "Daemon is not running.\n"
      exit 1
    end

  when '-i', '--pid'
    any_args_left?
    if is_daemon_running?
      puts daemon_pid
      exit 0
    else
      puts "Daemon is not running.\n"
      exit 1
    end

  when '-l', '--ls'
    any_args_left?
    refresh_listings
    exit 0

  when '-c', '--clean'
    any_args_left?
    refresh_listings(true)
    exit 0

  when '-s', '--sync'
    remote = is_next_arg_value? ? get_next_arg : DEFAULT_IMAGE_SERVER

    do_upload   = true if get_flag('-U') || get_flag('--upload')
    do_download = true if get_flag('-D') || get_flag('--download')
    do_upload = do_download = true unless do_upload || do_download

    do_thumb = true if get_flag('-T') || get_flag('--thumb')
    do_640   = true if get_flag('-N') || get_flag('--640')
    do_orig  = true if get_flag('-O') || get_flag('--orig')
    do_thumb = do_640 = do_orig = true unless do_thumb || do_640 || do_orig

    use_cache = true if get_flag('--use_cache')

    any_args_left?

    # Try to find local image directory
    if File.directory?(@@local_path)
      local = @@local_path
    elsif File.directory?('public/images')
      local = 'public/images'
    elsif File.directory?('images')
      local = 'images'
    elsif File.directory?('thumb') ||
          File.directory?('640') ||
          File.directory?('orig')
      local = '.'
    else
      puts "I cannot find your local images directory.\n" +
            "Please create it or use --local-path argument.\n"
      exit 1
    end
    puts "Local directory: #{local}\n"
    puts "Remote server: #{remote}\n"

    # Make sure subdirectories exist.
    if do_thumb && !File.directory?("#{local}/thumb")
      puts "Creating "#{local}/thumb\n"
      Dir.mkdir("#{local}/thumb\n")
    end
    if do_640 && !File.directory?("#{local}/640")
      puts "Creating "#{local}/640\n"
      Dir.mkdir("#{local}/640\n")
    end
    if do_orig && !File.directory?("#{local}/orig")
      puts "Creating "#{local}/orig\n"
      Dir.mkdir("#{local}/orig\n")
    end

    sync_command(local,remote, do_upload,do_download, do_thumb,do_640,do_orig, use_cache)
    exit 0

################################################################################

  when '-h', '--help'
    puts <<"EOH"

USAGE
  script/update_images --<mode> [args...]

MODES
  -d --start [delay]    Start the daemon (if not already started).
  -r --restart [delay]  Restart the daemon.
  -k --stop             Kill the daemon.
  -i --pid              Print the pid of the daemon (if running).
  -l --ls               Refresh the local list of images on the remote servers.
  -c --clean            Refresh the list and remove originals that are done.
  -s --sync [server]    Sync up the images at the given server.
  -h --help             Print this help message.

OPTIONS
  These can be used in any mode:
    -R --root <path>        Override rails root path.   /var/web/mo
    -F --pid-file <path>    Override pid file.          $root/tmp/pids/$0.pid
    -L --log-file <path>    Override log file.          $root/log/$0.log
    -P --local-path <path>  Override local image path.  $root/public/images
    -v --verbose            Turn on verbose messages.

  These can all be used in --sync mode:
    -U --upload            Only upload images to remote server.
    -D --download          Only download images from remote server.
    -T --thumb             Only update thumbnails.
    -N --640               Only update normal-size images.
    -O --orig              Only update originals.
       --use_cache         Just use cached file list (don't refresh).

DESCRIPTION
  This program is used to keep image servers in sync.  The primary mode is to
  run as a daemon on the main webserver along side the rails instances.  But
  it can also be run as a command-line utility from any machine.

DAEMON MODE
  It is started and monitored automatically by the monit daemon on the main
  webserver.  When first started, it gets a directory of all the images present
  locally, and it reads a list of files known to be present on the remote image
  servers.

  Every minute it wakes up and looks for new *original* images locally, and
  checks if any local images are missing on the remote servers.  It tries to
  upload a file 5 times before giving up on the server.  Once a server goes
  down, it will wait 10 minutes before trying it again.

  Every night at 3:00am a cronjob requests a full listing of images on the
  remote image servers and caches the result (using the --clean mode).  It
  ignores remote images that are a different size from local images.  (It
  considers images of size 0 not to exist at all, on either side.)  At this
  time it will delete all original images locally if they are confirmed present
  on the remote servers.

SYNC MODE
  When run as a command-line utility, it first grabs a directory of all images
  both locally and remotely.  If there are any size mismatches, it complains
  and ignores those images until you can decide which is correct.  Then it
  copies any images that are on one but not the other so that both machines
  wind up with identical copies.

  By default it will update both local and remote servers, and it will do all
  image types (thumbnails, normal-sized, and originals).  You can restrict it
  to just upload or just download, and you can tell it only to do thumbnails,
  originals, etc.

  Unlike the daemon, it copies all files of a given type in a single command,
  running an instance of tar on both machines connected via pipes in ssh.  This
  should be very efficient.

SSH PASSWORDS
  You must set up password-less ssh with each remote machine for this to work.
  Create a local key if you haven't already done so:

    ssh-keygen -t rsa

  (Just press return three times.)  Then copy it to each remote machine:

    ssh-copy-id -i ~/.ssh/id_rsa.pub user@server.url

FILES
  Servers are specified either by alias, or by scp-type syntax:

    user@host.url:path

  The aliases recognized currently are:

    dreamhost   velosa@images.mushroomobserver.org:images.mushroomobserver.org
    slicehost   mushroomobserver.org:/var/web/mo/public/images

  The defaults are:

    root        /var/web/mo
    pid file    /var/web/mo/tmp/pids/update_images.pid
    file lists  /var/web/mo/public/images/dreamhost.files
    local path  /var/web/mo/public/images
    server      dreamhost

EXAMPLES
  update_images --start 60
    Start daemon, telling it to check for new images every 60 seconds.

  update_images --restart 300
    Restart daemon, telling it to check for new images every 5 minutes.

  update_images --stop
    Stop daemon.

  update_images --ls
    Force daemon to refresh its list of images on the remote servers.  This
    normally happens once a day at 3am.

  update_images --sync dreamhost --upload
    Run this on slicehost to force it to upload any images missing on
    dreamhost.

  update_images --sync dreamhost --download --orig --local-path image_backup
    Run this on your local machine to update your backup copy of the original
    images in a directory called image_backup/orig.

  update_images --sync dreamhost --download --thumb
    Run this on your local machine to grab all the thumbnails for testing
    purposes.

  update_images --sync dreamhost
    Run this on a hypothetical second image server to sync them up: copy
    images missing on the second from the first, and vice versa.

EOH
    exit 0

  else
    puts "Invalid or missing mode.  Use -h or --help for list.\n"
    exit 1
end

